{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.18",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "tpu1vmV38",
      "dataSources": [
        {
          "sourceId": 3535844,
          "sourceType": "datasetVersion",
          "datasetId": 1707504
        },
        {
          "sourceId": 8831896,
          "sourceType": "datasetVersion",
          "datasetId": 5314260
        },
        {
          "sourceId": 205961,
          "sourceType": "modelInstanceVersion",
          "isSourceIdPinned": false,
          "modelInstanceId": 4694,
          "modelId": 2823
        },
        {
          "sourceId": 521642,
          "sourceType": "modelInstanceVersion",
          "isSourceIdPinned": false,
          "modelInstanceId": 410134,
          "modelId": 222398
        },
        {
          "sourceId": 521983,
          "sourceType": "modelInstanceVersion",
          "isSourceIdPinned": false,
          "modelInstanceId": 410138,
          "modelId": 279036
        }
      ],
      "dockerImageVersionId": 31091,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": [],
      "gpuType": "V28",
      "include_colab_link": true
    },
    "accelerator": "TPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "dcfa89ccee1440508e5251aef73a63cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0a7c407eaeab40cd95e6139c38b558dd"
            ],
            "layout": "IPY_MODEL_47c5635b8caa43b9b3202f0201f7c85d"
          }
        },
        "1c1f2b5c5e8e46c4b4f40a8efbf1f7b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9b19402fee204acc9dfff9831b499682",
            "placeholder": "​",
            "style": "IPY_MODEL_a41fa251052e4326a511bd51c749a826",
            "value": "<center> <img\nsrc=https://www.kaggle.com/static/images/site-logo.png\nalt='Kaggle'> <br> Create an API token from <a\nhref=\"https://www.kaggle.com/settings/account\" target=\"_blank\">your Kaggle\nsettings page</a> and paste it below along with your Kaggle username. <br> </center>"
          }
        },
        "0fbbbad07ef34632adb18bb076eac5f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextView",
            "continuous_update": true,
            "description": "Username:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_4b779355e40a44c782bb95c0c1c90ebd",
            "placeholder": "​",
            "style": "IPY_MODEL_fe4a9401176d44eca787ec1e850f85fc",
            "value": "bakeronit"
          }
        },
        "1b8b19c32c45415c80b7cf9569266177": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_13c2d44430bd4c238051bc51b739c26e",
            "placeholder": "​",
            "style": "IPY_MODEL_d2cf7bfa346e41a1a526b88b91f94dbd",
            "value": ""
          }
        },
        "6c48c84f1b8b45f1b3f936c2ea868cac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_4938ceab3ac84c31a475b200525624b8",
            "style": "IPY_MODEL_1e5e298e0e64475f94dea92ff71a540b",
            "tooltip": ""
          }
        },
        "e7177804054c45358738445bffe214f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0fde1f45a0d3404396820d393da3dd97",
            "placeholder": "​",
            "style": "IPY_MODEL_dd832102388d4a0396290e5835a6124a",
            "value": "\n<b>Thank You</b></center>"
          }
        },
        "47c5635b8caa43b9b3202f0201f7c85d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "9b19402fee204acc9dfff9831b499682": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a41fa251052e4326a511bd51c749a826": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4b779355e40a44c782bb95c0c1c90ebd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe4a9401176d44eca787ec1e850f85fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "13c2d44430bd4c238051bc51b739c26e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d2cf7bfa346e41a1a526b88b91f94dbd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4938ceab3ac84c31a475b200525624b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e5e298e0e64475f94dea92ff71a540b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "0fde1f45a0d3404396820d393da3dd97": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd832102388d4a0396290e5835a6124a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5f7f412c09c44df9bcb5c7fa1f5792fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b2c49a5e022d4e01aff5d217c43f682d",
            "placeholder": "​",
            "style": "IPY_MODEL_89485b921bb448d497ad524785070f1d",
            "value": "Connecting..."
          }
        },
        "b2c49a5e022d4e01aff5d217c43f682d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "89485b921bb448d497ad524785070f1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0a7c407eaeab40cd95e6139c38b558dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d11e74ae6b2048ec83305f10137bedf0",
            "placeholder": "​",
            "style": "IPY_MODEL_c3d3dafec7274441b147b85592bd0565",
            "value": "Kaggle credentials successfully validated."
          }
        },
        "d11e74ae6b2048ec83305f10137bedf0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3d3dafec7274441b147b85592bd0565": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bakeronit/note-nbviewer/blob/master/gdg_ai_for_science_finetune.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fine-Tuning a Large Language Model on Your Own Data (Notebook 1)\n",
        "\n",
        "This is part of a series run by the [GDG AI for Science](https://gdg.community.dev/gdg-ai-for-science-australia/)\n",
        "\n",
        "**Notebook 1:** Fine Tune with KerasHub (TPU accelerator required)\n",
        "\n",
        "![You are here](https://colab.research.google.com/assets/colab-badge.svg) or [![Kaggle](https://kaggle.com/static/images/open-in-kaggle.svg)](https://www.kaggle.com/code/astrobutter/gdg-ai-for-science-finetuning)\n",
        "\n",
        "Notebook 2: Fine Tune with Transformers (GPU accelerator required)\n",
        "\n",
        "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1sJviybARN36t3d_i-gfmc0zDs51WDgzz?usp=sharing) or [![Kaggle](https://kaggle.com/static/images/open-in-kaggle.svg)](https://www.kaggle.com/code/astrobutter/gdg-ai-for-science-finetuning-transformers)\n",
        "\n",
        "Notebook 3: RAG workflow (GPU recommended)\n",
        "\n",
        "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1vA3f3XdLB3nvczP4gRuTMwWMfSkXT1ex?usp=sharing) or [![Kaggle](https://kaggle.com/static/images/open-in-kaggle.svg)](https://www.kaggle.com/code/astrobutter/gdg-ai-for-science-finetuning-rag)\n",
        "\n",
        "## Prerequisites\n",
        "* Familiarity with Python, including functions and the pandas library.\n",
        "\n",
        "* Access to a computing environment with a GPU or TPU (like a Kaggle Notebook or Google Colab).\n",
        "\n",
        "## Learning Objectives\n",
        "* Understand the concepts of pre-training and fine-tuning for Large Language Models (LLMs).\n",
        "\n",
        "* Recognize the hardware requirements and limitations (GPU/TPU/CPU) for training.\n",
        "\n",
        "* Prepare a custom dataset for fine-tuning.\n",
        "\n",
        "* Fine-tune an LLM using Keras with a TPU backend.\n",
        "\n",
        "* Fine-tune an LLM using the transformers library with a GPU backend.\n",
        "\n",
        "* Understand the difference between full fine-tuning and Parameter-Efficient Fine-Tuning (PEFT) with LoRA.\n",
        "\n",
        "* Evaluate the model's performance by comparing responses before and after fine-tuning.\n",
        "\n",
        "* Compare a RAG workflow with Fine Tuning\n",
        "\n",
        "\n",
        "## What is a Large Language Model (LLM)? 🤖\n",
        "Think of a pre-trained LLM like a brilliant new research assistant who has read nearly the entire public internet. They have a vast general knowledge and can write essays, summarize articles, and answer questions on a huge range of topics. However, they haven't read your lab's specific protocols, your private research data, or the niche publications in your specialized field, and they make a lot of mistakes whilst trying to appear confident that they are correct (even when they are not).\n",
        "\n",
        "This \"general knowledge\" comes from a process called pre-training, where the model is shown trillions of words of text and learns the patterns, grammar, and facts of human language.\n",
        "\n",
        "## What is Fine-Tuning? 🎯\n",
        "Fine-tuning is the process of taking that pre-trained model and training it for a bit longer on your own, smaller, domain-specific dataset, or teaching it a specific task. It's like giving your new research assistant a curated stack of your lab's most important papers and data. You aren't teaching them language from scratch; you're adapting their existing knowledge to your specific needs.\n",
        "\n",
        "Through fine-tuning, the model can learn your domain's specific vocabulary, understand relationships between concepts in your field, and can adopt a specific style or format for its responses.\n",
        "\n",
        "## Hardware Requirements 🚀\n",
        "Training and fine-tuning LLMs involves billions of calculations. A standard computer processor (CPU) can handle complex, sequential, singular tasks. However, training requires thousands of simple tasks at the exact same time.\n",
        "\n",
        "This is where Graphics Processing Units (GPUs) and Tensor Processing Units (TPUs) come in. They are specialised chips designed for massive parallel computation, making them great for deep learning. Fine-tuning even a small LLM is practically impossible without one. For this lesson, we'll use Kaggle's free-tier TPUs and GPUs.\n",
        "\n",
        "## Frameworks and Architectures\n",
        "\n",
        "### Model Architecture (The \"Brains\")\n",
        "This is the design of the neural network itself. Examples include Gemma, GPT-2, Llama, etc. These are the pre-trained models we will adapt.\n",
        "\n",
        "### Framework\n",
        "These are the software libraries that provide the tools to load, manipulate, and train the models. We will use two of the most popular frameworks: **Keras** (a user-friendly, high-level API) and **Hugging Face transformers** (the de-facto industry standard, known for its power and flexibility).\n",
        "\n",
        "You must use a framework that supports the model architecture you want to work with.\n"
      ],
      "metadata": {
        "id": "cPZ5-M3vA_Oo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Example 1: Fine-Tuning Gemma with Keras on a TPU\n",
        "In this first example, we'll perform a full fine-tuning of Google's Gemma model. This means we will be updating all of the model's weights using our custom data. We'll use the Keras framework with a JAX backend, which is highly optimized for running on TPUs.\n",
        "\n",
        "## Setup and Environment Configuration"
      ],
      "metadata": {
        "id": "IKwgxr_zA_Oq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Kaggle API Token Setup\n",
        "\n",
        "To download [Gemma models](https://www.kaggle.com/models/google/gemma) (or other datasets/models) from Kaggle directly into Colab or your local computer, you need a Kaggle API token.\n",
        "\n",
        "**Steps to get your `kaggle.json` token:**\n",
        "   1. Go to your Kaggle account page: [https://www.kaggle.com/](https://www.kaggle.com/)\n",
        "   2. Log in or create an account if you don't have one.\n",
        "   3. Click on your profile picture/icon in the top right corner, then select **\"Settings\"**.\n",
        "   4. Scroll down to the **\"API\"** section.\n",
        "   5. Click **\"Create New Token\"**. This will download a file named `kaggle.json` to your computer.\n",
        "\n",
        "   This file just contains some text with your username and an *API Key*. Treat this like a username and password. You can \"revoke\" access easily and often have fine-grain control of what the Key can access.\n",
        "\n",
        "   `{\"username\":\"astrobutter\",\"key\":\"abcdefghijk1234567890\"}`\n",
        "\n",
        "**Accept Gemma terms of service**\n",
        "\n",
        "   6. Visit https://www.kaggle.com/models/google/gemma and accept the usage license (this is common for many model families)\n",
        "  \n",
        "### Log in to Kaggle and basic imports\n",
        "Now we can login to Kaggle. Download any data and models we need. And then import our basic libraries and configure the environment to ensure Keras uses the JAX backend and can access the TPU's full memory."
      ],
      "metadata": {
        "id": "9lQL5w-S85YT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import basic libraries for file handling and data manipulation\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "# Login to Kaggle Hub - get credentials from https://www.kaggle.com/settings\n",
        "import kagglehub\n",
        "kagglehub.login()"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-25T00:34:36.901234Z",
          "iopub.execute_input": "2025-08-25T00:34:36.901778Z",
          "iopub.status.idle": "2025-08-25T00:34:40.120910Z",
          "shell.execute_reply.started": "2025-08-25T00:34:36.901747Z",
          "shell.execute_reply": "2025-08-25T00:34:40.116373Z"
        },
        "id": "V2pYODl0A_Oq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103,
          "referenced_widgets": [
            "dcfa89ccee1440508e5251aef73a63cc",
            "1c1f2b5c5e8e46c4b4f40a8efbf1f7b1",
            "0fbbbad07ef34632adb18bb076eac5f5",
            "1b8b19c32c45415c80b7cf9569266177",
            "6c48c84f1b8b45f1b3f936c2ea868cac",
            "e7177804054c45358738445bffe214f9",
            "47c5635b8caa43b9b3202f0201f7c85d",
            "9b19402fee204acc9dfff9831b499682",
            "a41fa251052e4326a511bd51c749a826",
            "4b779355e40a44c782bb95c0c1c90ebd",
            "fe4a9401176d44eca787ec1e850f85fc",
            "13c2d44430bd4c238051bc51b739c26e",
            "d2cf7bfa346e41a1a526b88b91f94dbd",
            "4938ceab3ac84c31a475b200525624b8",
            "1e5e298e0e64475f94dea92ff71a540b",
            "0fde1f45a0d3404396820d393da3dd97",
            "dd832102388d4a0396290e5835a6124a",
            "5f7f412c09c44df9bcb5c7fa1f5792fa",
            "b2c49a5e022d4e01aff5d217c43f682d",
            "89485b921bb448d497ad524785070f1d",
            "0a7c407eaeab40cd95e6139c38b558dd",
            "d11e74ae6b2048ec83305f10137bedf0",
            "c3d3dafec7274441b147b85592bd0565"
          ]
        },
        "outputId": "94336fd2-891f-420e-8132-f75cd839e31e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://www.kaggle.com/static/images/site-logo.png\\nalt=\\'Kaggle…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dcfa89ccee1440508e5251aef73a63cc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kaggle credentials set.\n",
            "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.12), please consider upgrading to the latest version (0.3.13).\n",
            "Kaggle credentials successfully validated.\n"
          ]
        }
      ],
      "execution_count": 1
    },
    {
      "cell_type": "code",
      "source": [
        "# Download models and data from Kaggle\n",
        "path_gemma = kagglehub.model_download(\"keras/gemma3/keras/gemma3_instruct_270m\")\n",
        "path_gpt = kagglehub.model_download(\"keras/gpt2/keras/gpt2_base_en\")\n",
        "path_data = kagglehub.dataset_download(\"gpreda/medquad\")"
      ],
      "metadata": {
        "id": "sLJjsPVkZm3w"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Update python libraries to use TPU in a kaggle/colab notebook\n",
        "# jax 0.6.2 and keras-hub 0.21.1 seem to work\n",
        "!pip install -U pip -q\n",
        "!pip install -U \"jax[tpu]\"==0.6.2 -q\n",
        "!pip install keras-hub==0.21.1 -U -q"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-25T00:34:40.123852Z",
          "iopub.execute_input": "2025-08-25T00:34:40.124183Z",
          "iopub.status.idle": "2025-08-25T00:35:13.458905Z",
          "shell.execute_reply.started": "2025-08-25T00:34:40.124158Z",
          "shell.execute_reply": "2025-08-25T00:35:13.453156Z"
        },
        "id": "lNtohrMMA_Or",
        "outputId": "97521179-a79e-42f3-94f5-7bc753676592",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.8 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.2/1.8 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m1.4/1.8 MB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "execution_count": 3
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Environment Setup for Keras with JAX on a TPU ---\n",
        "\n",
        "# Keras is a high-level API that can run on different backends like TensorFlow, PyTorch, or JAX.\n",
        "# JAX is a high-performance library from Google that is especially efficient on TPUs.\n",
        "# We explicitly tell Keras to use JAX for all its computations.\n",
        "os.environ[\"KERAS_BACKEND\"] = \"jax\"\n",
        "\n",
        "# This command instructs JAX to pre-allocate all available TPU memory.\n",
        "# This can prevent memory fragmentation and speed up computations, but it means this notebook\n",
        "# will have exclusive use of the TPU.\n",
        "os.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"] = \"1.00\""
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-25T00:35:13.460748Z",
          "iopub.execute_input": "2025-08-25T00:35:13.460982Z",
          "iopub.status.idle": "2025-08-25T00:35:13.471625Z",
          "shell.execute_reply.started": "2025-08-25T00:35:13.460954Z",
          "shell.execute_reply": "2025-08-25T00:35:13.467107Z"
        },
        "id": "jgXa_7wmA_Or"
      },
      "outputs": [],
      "execution_count": 4
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Import Deep Learning Libraries ---\n",
        "\n",
        "# Import JAX and configure it to use the TPU.\n",
        "import jax\n",
        "jax.config.update('jax_platform_name', 'tpu')\n",
        "print(f\"JAX is running on {jax.devices()[0].device_kind}\")\n",
        "\n",
        "# Import our main deep learning frameworks: Keras and keras-hub (forerly keras-nlp) for LLM-specific tools.\n",
        "import keras\n",
        "import keras_hub\n",
        "\n",
        "# bfloat16 uses less memory than the standard float32, which helps our model train faster on a TPU without a major loss in accuracy.\n",
        "# keras.config.set_floatx(\"bfloat16\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-25T00:35:13.474298Z",
          "iopub.execute_input": "2025-08-25T00:35:13.474555Z",
          "iopub.status.idle": "2025-08-25T00:35:39.367523Z",
          "shell.execute_reply.started": "2025-08-25T00:35:13.474529Z",
          "shell.execute_reply": "2025-08-25T00:35:39.361564Z"
        },
        "id": "fg0kNh-WA_Os",
        "outputId": "f77b6de6-77a6-4736-d0f5-d04761d02e5f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "JAX is running on TPU v2\n"
          ]
        }
      ],
      "execution_count": 5
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Loading and Preparation\n",
        "An LLM needs to be trained on structured examples. For a question-answering task, this means clear pairs of \"prompts\" (questions) and \"responses\" (answers). We'll load the [medquad](https://www.kaggle.com/datasets/gpreda/medquad) dataset, which contains medical questions and answers, and then create a small, targeted subset for our task."
      ],
      "metadata": {
        "id": "TIx2dLzqA_Os"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and subset the data for training\n",
        "df = pd.read_csv(path_data+\"/medquad.csv\")\n",
        "# data = df.sample(n=100, random_state=42)\n",
        "\n",
        "# For this workshop, we want the fine-tuning process to be fast and the results to be obvious.\n",
        "# So, we will \"cheat\" by creating a very small, highly specific dataset focused only on \"pernicious anemia\".\n",
        "# In a real-world project, you would use a much larger and more diverse dataset representing your entire domain.\n",
        "df_subset_mask = df['question'].str.contains('pernicious anemia', case=False, na=False) | \\\n",
        "                         df['answer'].str.contains('pernicious anemia', case=False, na=False) | \\\n",
        "                         df['focus_area'].str.contains('pernicious anemia', case=False, na=False)\n",
        "df_subset = df[df_subset_mask]\n",
        "\n",
        "# Preview the first few lines of the data\n",
        "df_subset.head(2)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-25T00:35:39.368354Z",
          "iopub.execute_input": "2025-08-25T00:35:39.368855Z",
          "iopub.status.idle": "2025-08-25T00:35:40.095267Z",
          "shell.execute_reply.started": "2025-08-25T00:35:39.368829Z",
          "shell.execute_reply": "2025-08-25T00:35:40.088765Z"
        },
        "id": "40d1d0JOA_Os",
        "outputId": "7dd2fc42-fc74-48cd-cccf-05a1809c71ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               question  \\\n",
              "1132  Who is at risk for Gastrointestinal Carcinoid ...   \n",
              "3017      What is (are) Autoimmune atrophic gastritis ?   \n",
              "\n",
              "                                                 answer     source  \\\n",
              "1132  Health history can affect the risk of gastroin...  CancerGov   \n",
              "3017  Autoimmune atrophic gastritis is an autoimmune...       GARD   \n",
              "\n",
              "                             focus_area  \n",
              "1132  Gastrointestinal Carcinoid Tumors  \n",
              "3017      Autoimmune atrophic gastritis  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e8ede116-9766-48d7-8e0b-9d5fc215bfe1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>answer</th>\n",
              "      <th>source</th>\n",
              "      <th>focus_area</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1132</th>\n",
              "      <td>Who is at risk for Gastrointestinal Carcinoid ...</td>\n",
              "      <td>Health history can affect the risk of gastroin...</td>\n",
              "      <td>CancerGov</td>\n",
              "      <td>Gastrointestinal Carcinoid Tumors</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3017</th>\n",
              "      <td>What is (are) Autoimmune atrophic gastritis ?</td>\n",
              "      <td>Autoimmune atrophic gastritis is an autoimmune...</td>\n",
              "      <td>GARD</td>\n",
              "      <td>Autoimmune atrophic gastritis</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e8ede116-9766-48d7-8e0b-9d5fc215bfe1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e8ede116-9766-48d7-8e0b-9d5fc215bfe1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e8ede116-9766-48d7-8e0b-9d5fc215bfe1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-396a15d5-bb90-47cd-837b-b915a72ec982\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-396a15d5-bb90-47cd-837b-b915a72ec982')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-396a15d5-bb90-47cd-837b-b915a72ec982 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_subset",
              "summary": "{\n  \"name\": \"df_subset\",\n  \"rows\": 21,\n  \"fields\": [\n    {\n      \"column\": \"question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 21,\n        \"samples\": [\n          \"Who is at risk for Gastrointestinal Carcinoid Tumors? ?\",\n          \"What are the genetic changes related to Graves disease ?\",\n          \"What is (are) vitiligo ?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"answer\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 21,\n        \"samples\": [\n          \"Health history can affect the risk of gastrointestinal carcinoid tumors. Anything that increases a person's chance of developing a disease is called a risk factor. Having a risk factor does not mean that you will get cancer; not having risk factors doesnt mean that you will not get cancer. Talk to your doctor if you think you may be at risk.    Risk factors for GI carcinoid tumors include the following:         - Having a family history of multiple endocrine neoplasia type 1 (MEN1) syndrome or neurofibromatosis type 1 (NF1) syndrome.     - Having certain conditions that affect the stomach's ability to make stomach acid, such as atrophic gastritis, pernicious anemia, or Zollinger-Ellison syndrome.\",\n          \"Graves disease is thought to result from a combination of genetic and environmental factors. Some of these factors have been identified, but many remain unknown.  Graves disease is classified as an autoimmune disorder, one of a large group of conditions that occur when the immune system attacks the body's own tissues and organs. In people with Graves disease, the immune system creates a protein (antibody) called thyroid-stimulating immunoglobulin (TSI). TSI signals the thyroid to increase its production of hormones abnormally. The resulting overactivity of the thyroid causes many of the signs and symptoms of Graves disease. Studies suggest that immune system abnormalities also underlie Graves ophthalmopathy and pretibial myxedema.  People with Graves disease have an increased risk of developing other autoimmune disorders, including rheumatoid arthritis, pernicious anemia, systemic lupus erythematosus, Addison disease, celiac disease, type 1 diabetes, and vitiligo.  Variations in many genes have been studied as possible risk factors for Graves disease. Some of these genes are part of a family called the human leukocyte antigen (HLA) complex. The HLA complex helps the immune system distinguish the body's own proteins from proteins made by foreign invaders (such as viruses and bacteria). Other genes that have been associated with Graves disease help regulate the immune system or are involved in normal thyroid function. Most of the genetic variations that have been discovered are thought to have a small impact on a person's overall risk of developing this condition.  Other, nongenetic factors are also believed to play a role in Graves disease. These factors may trigger the condition in people who are at risk, although the mechanism is unclear. Potential triggers include changes in sex hormones (particularly in women), viral or bacterial infections, certain medications, and having too much or too little iodine (a substance critical for thyroid hormone production). Smoking increases the risk of eye problems and is associated with more severe eye abnormalities in people with Graves disease.\",\n          \"Vitiligo is a condition that causes patchy loss of skin coloring (pigmentation). The average age of onset of vitiligo is in the mid-twenties, but it can appear at any age. It tends to progress over time, with larger areas of the skin losing pigment. Some people with vitiligo also have patches of pigment loss affecting the hair on their scalp or body.  Researchers have identified several forms of vitiligo. Generalized vitiligo (also called nonsegmental vitiligo), which is the most common form, involves loss of pigment (depigmentation) in patches of skin all over the body. Depigmentation typically occurs on the face, neck, and scalp, and around body openings such as the mouth and genitals. Sometimes pigment is lost in mucous membranes, such as the lips. Loss of pigmentation is also frequently seen in areas that tend to experience rubbing, impact, or other trauma, such as the hands, arms, and places where bones are close to the skin surface (bony prominences). Another form called segmental vitiligo is associated with smaller patches of depigmented skin that appear on one side of the body in a limited area; this occurs in about 10 percent of affected individuals.  Vitiligo is generally considered to be an autoimmune disorder. Autoimmune disorders occur when the immune system attacks the body's own tissues and organs. In people with vitiligo the immune system appears to attack the pigment cells (melanocytes) in the skin. About 15 to 25 percent of people with vitiligo are also affected by at least one other autoimmune disorder, particularly autoimmune thyroid disease, rheumatoid arthritis, type 1 diabetes, psoriasis, pernicious anemia, Addison disease, or systemic lupus erythematosus.  In the absence of other autoimmune conditions, vitiligo does not affect general health or physical functioning. However, concerns about appearance and ethnic identity are significant issues for many affected individuals.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"source\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"CancerGov\",\n          \"GARD\",\n          \"NIDDK\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"focus_area\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 11,\n        \"samples\": [\n          \"Stiff-Person Syndrome\",\n          \"Gastrointestinal Carcinoid Tumors\",\n          \"Adrenal Insufficiency and Addison's Disease\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "execution_count": 6
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Format the Data for the LLM\n",
        "We want to train OUR model on a dataset of prompt-response pairs.\n",
        "We'll write a simple function to convert our DataFrame into the dictionary format **required** by the model we choose to use.\n",
        "For best results, you should format the prompt and response to match the template the model was originally trained on. This often involves special tokens like `'<start_of_turn>user'` and`'<start_of_turn>model'`. Check the [Gemma model card](https://ai.google.dev/gemma/docs/core/prompt-structure) for details."
      ],
      "metadata": {
        "id": "DdC6CTujA_Ot"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper function to transform our dataframe into the required format.\n",
        "def format_data(df):\n",
        "    prompts = []\n",
        "    responses = []\n",
        "    for index, row in df.iterrows():\n",
        "        question = row['question']\n",
        "        response = row['answer']\n",
        "        if question and response:\n",
        "             # prompts.append(f\"<start_of_turn>user\\nInstruction:\\nAnswer the following question.\\nQuestion:{question}\\n<end_of_turn>\")\n",
        "             # responses.append(f\"<start_of_turn>model\\nResponse:{response}\\n<end_of_turn>\")\n",
        "            prompts.append(f\"{question}\")\n",
        "            responses.append(f\"{response}\")\n",
        "\n",
        "    data_to_preprocess = {\"prompts\": prompts, \"responses\": responses}\n",
        "    return data_to_preprocess\n",
        "\n",
        "# Apply the formatting to our data.\n",
        "formatted_data = format_data(df_subset)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-25T00:35:40.096049Z",
          "iopub.execute_input": "2025-08-25T00:35:40.096267Z",
          "iopub.status.idle": "2025-08-25T00:35:40.108091Z",
          "shell.execute_reply.started": "2025-08-25T00:35:40.096245Z",
          "shell.execute_reply": "2025-08-25T00:35:40.104458Z"
        },
        "id": "zl72Zo-vA_Ot"
      },
      "outputs": [],
      "execution_count": 7
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading the Pre-Trained Model\n",
        "Now, we'll load the pre-trained Gemma model. We are using a Gemma3CausalLM, which is a \"Causal Language Model.\" This means it works by predicting the very next word (or \"token\") in a sequence based on the words that came before it. This is the fundamental mechanism behind text generation."
      ],
      "metadata": {
        "id": "aucuc0FtA_Ot"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the Gemma3 model\n",
        "# `from_preset` is a convenient Keras function to load a model with its standard configuration.\n",
        "# This includes the model architecture itself, the pre-trained weights, and the tokenizer\n",
        "# which converts text into numbers the model can understand.\n",
        "# We are loading a smaller 270 Million parameter version of Gemma 3, which is suitable for quick fine-tuning.\n",
        "print(\"Loading model...\")\n",
        "causal_lm = keras_hub.models.Gemma3CausalLM.from_preset(path_gemma)\n",
        "\n",
        "# The .summary() method gives us a look at the model's architecture.\n",
        "# Pay attention to the \"Total params\" and \"Trainable params\". In this full fine-tuning\n",
        "# example, they will be the same, meaning we are updating every part of the model.\n",
        "causal_lm.summary()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-25T00:35:40.119226Z",
          "iopub.execute_input": "2025-08-25T00:35:40.119654Z",
          "iopub.status.idle": "2025-08-25T00:35:57.016577Z",
          "shell.execute_reply.started": "2025-08-25T00:35:40.119629Z",
          "shell.execute_reply": "2025-08-25T00:35:57.010037Z"
        },
        "id": "9PLE9JinA_Ot",
        "outputId": "b94ccf33-bb71-47a6-aecd-f2bbddf38215",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 414
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mPreprocessor: \"gemma3_causal_lm_preprocessor\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Preprocessor: \"gemma3_causal_lm_preprocessor\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                                                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m                                  Config\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ gemma3_tokenizer (\u001b[38;5;33mGemma3Tokenizer\u001b[0m)                            │                      Vocab size: \u001b[38;5;34m262,144\u001b[0m │\n",
              "└───────────────────────────────────────────────────────────────┴──────────────────────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                                                  </span>┃<span style=\"font-weight: bold\">                                   Config </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ gemma3_tokenizer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Gemma3Tokenizer</span>)                            │                      Vocab size: <span style=\"color: #00af00; text-decoration-color: #00af00\">262,144</span> │\n",
              "└───────────────────────────────────────────────────────────────┴──────────────────────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"gemma3_causal_lm\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"gemma3_causal_lm\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ padding_mask (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
              "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
              "│ token_ids (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
              "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
              "│ gemma3_backbone               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m640\u001b[0m)         │     \u001b[38;5;34m268,098,176\u001b[0m │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n",
              "│ (\u001b[38;5;33mGemma3Backbone\u001b[0m)              │                           │                 │ token_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
              "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
              "│ token_embedding               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m262144\u001b[0m)      │     \u001b[38;5;34m167,772,160\u001b[0m │ gemma3_backbone[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "│ (\u001b[38;5;33mReversibleEmbedding\u001b[0m)         │                           │                 │                            │\n",
              "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ padding_mask (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
              "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
              "│ token_ids (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
              "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
              "│ gemma3_backbone               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">640</span>)         │     <span style=\"color: #00af00; text-decoration-color: #00af00\">268,098,176</span> │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Gemma3Backbone</span>)              │                           │                 │ token_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
              "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
              "│ token_embedding               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">262144</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">167,772,160</span> │ gemma3_backbone[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReversibleEmbedding</span>)         │                           │                 │                            │\n",
              "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m268,098,176\u001b[0m (1022.71 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">268,098,176</span> (1022.71 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m268,098,176\u001b[0m (1022.71 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">268,098,176</span> (1022.71 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 8
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test Before Fine-Tuning (Establish a Baseline)\n",
        "It's crucial to see how the model performs before we fine-tune it. This gives us a baseline to measure our improvements against. We will ask it a question about our topic and see what its general knowledge provides."
      ],
      "metadata": {
        "id": "JzScXd3EA_Ot"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set a prompt\n",
        "prompt = \"What is pernicious anemia?\""
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-25T00:35:57.017334Z",
          "iopub.execute_input": "2025-08-25T00:35:57.017573Z",
          "iopub.status.idle": "2025-08-25T00:35:57.029015Z",
          "shell.execute_reply.started": "2025-08-25T00:35:57.017549Z",
          "shell.execute_reply": "2025-08-25T00:35:57.023001Z"
        },
        "id": "7VxOre6fA_Ot"
      },
      "outputs": [],
      "execution_count": 9
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Sending prompt to model...\")\n",
        "\n",
        "# The .generate() method takes our text prompt and produces a response.\n",
        "response_raw = causal_lm.generate(prompt)\n",
        "\n",
        "print(f\"{response_raw}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-25T00:35:57.030286Z",
          "iopub.execute_input": "2025-08-25T00:35:57.030497Z",
          "iopub.status.idle": "2025-08-25T00:36:15.008627Z",
          "shell.execute_reply.started": "2025-08-25T00:35:57.030476Z",
          "shell.execute_reply": "2025-08-25T00:36:15.001371Z"
        },
        "id": "nbV3to0oA_Ot",
        "outputId": "2c73b69a-2a28-47af-8cc3-f2b3ac564652",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sending prompt to model...\n",
            "What is pernicious anemia?\n",
            "\n",
            "The answer is that it is a condition where the body's ability to produce enough red blood cells is impaired. This can lead to a variety of symptoms, including fatigue, weakness, shortness of breath, and dizziness.\n",
            "\n",
            "What is pernicious anemia?\n",
            "\n",
            "The answer is that it is a condition where the body's ability to produce enough red blood cells is impaired. This can lead to a variety of symptoms, including fatigue, weakness, shortness of breath, and dizziness.\n",
            "\n",
            "What is the main cause of pernicious anemia?\n",
            "\n",
            "The answer is that it is a condition where the body's ability to produce enough red blood cells is impaired. This can lead to a variety of symptoms, including fatigue, weakness, shortness of breath, and dizziness.\n",
            "\n",
            "What is the main symptom of pernicious anemia?\n",
            "\n",
            "The answer is that it is a condition where the body's ability to produce enough red blood cells is impaired. This can lead to a variety of symptoms, including fatigue, weakness, shortness of breath, and dizziness.\n",
            "\n",
            "What is the main cause of pernicious anemia?\n",
            "\n",
            "The answer is that it is a condition where the body's ability to produce enough red blood cells is impaired. This can lead to a variety of symptoms, including fatigue, weakness, shortness of breath, and dizziness.\n",
            "\n",
            "What is the main symptom of pernicious anemia?\n",
            "\n",
            "The answer is that it is a condition where the body's ability to produce enough red blood cells is impaired. This can lead to a variety of symptoms, including fatigue, weakness, shortness of breath, and dizziness.\n",
            "\n",
            "What is the main cause of pernicious anemia?\n",
            "\n",
            "The answer is that it is a condition where the body's ability to produce enough red blood cells is impaired. This can lead to a variety of symptoms, including fatigue, weakness, shortness of breath, and dizziness.\n",
            "\n",
            "What is the main symptom of pernicious anemia?\n",
            "\n",
            "The answer is that it is a condition where the body's ability to produce enough red blood cells is impaired. This can lead to a variety of symptoms, including fatigue, weakness, shortness of breath, and dizziness.\n",
            "\n",
            "What is the main cause of pernicious anemia?\n",
            "\n",
            "The answer is that it is a condition where the body's ability to produce enough red blood cells is impaired. This can lead to a variety of symptoms, including fatigue, weakness, shortness of breath, and dizziness.\n",
            "\n",
            "What is the main symptom of pernicious anemia?\n",
            "\n",
            "The answer is that it is a condition where the body's ability to produce enough red blood cells is impaired. This can lead to a variety of symptoms, including fatigue, weakness, shortness of breath, and dizziness.\n",
            "\n",
            "What is the main cause of pernicious anemia?\n",
            "\n",
            "The answer is that it is a condition where the body's ability to produce enough red blood cells is impaired. This can lead to a variety of symptoms, including fatigue, weakness, shortness of breath, and dizziness.\n",
            "\n",
            "What is the main symptom of pernicious anemia?\n",
            "\n",
            "The answer is that it is a condition where the body's ability to produce enough red blood cells is impaired. This can lead to a variety of symptoms, including fatigue, weakness, shortness of breath, and dizziness.\n",
            "\n",
            "What is the main cause of pernicious anemia?\n",
            "\n",
            "The answer is that it is a condition where the body's ability to produce enough red blood cells is impaired. This can lead to a variety of symptoms, including fatigue, weakness, shortness of breath, and dizziness.\n",
            "\n",
            "What is the main symptom of pernicious anemia?\n",
            "\n",
            "The answer is that it is a condition where the body's ability to produce enough red blood cells is impaired. This can lead to a variety of symptoms, including fatigue, weakness, shortness of breath, and dizziness.\n",
            "\n",
            "What is the main cause of pernicious anemia?\n",
            "\n",
            "The answer is that it is a condition where the body's ability to produce enough red blood cells is impaired. This can lead to a variety of symptoms, including fatigue, weakness, shortness of breath, and dizziness.\n",
            "\n",
            "What is the main cause of pernicious anemia?\n",
            "\n",
            "The answer is that it is a condition where the body's ability to produce enough red blood cells is impaired. This can lead to a variety of symptoms, including fatigue, weakness, shortness of breath, and dizziness.\n",
            "\n",
            "What is the main symptom of pernicious anemia?\n",
            "\n",
            "The answer is that it is a condition where the body's ability to produce enough red blood cells is impaired. This can lead to a variety of symptoms, including fatigue, weakness, shortness of breath, and dizziness.\n",
            "\n",
            "What is the main cause of pernicious anemia?\n",
            "\n",
            "The answer is that it is a condition where the body's ability to produce enough red blood cells is impaired. This can lead to a variety of symptoms, including fatigue, weakness, shortness of breath, and dizziness.\n",
            "\n",
            "What is the main cause of pernicious anemia?\n",
            "\n",
            "The answer is that it is a condition where the body's ability to produce enough red blood cells is impaired. This can lead to a variety of symptoms\n"
          ]
        }
      ],
      "execution_count": 10
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compile and Fine-Tune the Model\n",
        "Now we need to enable our model to be modified. Then we need to \"compile\" the model with our training options. Then we can calll .fit() to begin fine-tuning on our data."
      ],
      "metadata": {
        "id": "dyB7Y9KdA_Ot"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Enable Low-Rank Adaptation (LoRA) for parameter efficient fine-tuning.\n",
        "# LoRA freezes all weights on the backbone except for specific attention layer components\n",
        "causal_lm.backbone.enable_lora(rank=16)\n",
        "print(f\"Number of trainable weights after LoRA: {len(causal_lm.trainable_weights)}\")\n",
        "print(f\"Number of non-trainable weights after LoRA: {len(causal_lm.non_trainable_weights)}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-25T00:39:24.239664Z",
          "iopub.execute_input": "2025-08-25T00:39:24.240041Z",
          "iopub.status.idle": "2025-08-25T00:39:24.252476Z",
          "shell.execute_reply.started": "2025-08-25T00:39:24.240011Z",
          "shell.execute_reply": "2025-08-25T00:39:24.246813Z"
        },
        "id": "rrb5z5kjA_Ot",
        "outputId": "3420e1fb-b131-4d73-e330-7888e3155855",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of trainable weights after LoRA: 72\n",
            "Number of non-trainable weights after LoRA: 236\n"
          ]
        }
      ],
      "execution_count": 11
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Compiling the model...\")\n",
        "causal_lm.compile(\n",
        "    # The optimizer is the algorithm that updates the model's weights to minimize the loss.\n",
        "    # Adam is a very popular and effective general-purpose optimizer.\n",
        "    # The `learning_rate` is the single most important hyperparameter. It controls the size of the\n",
        "    # weight updates. Too large, and the training can become unstable; too small, and it will be too slow.\n",
        "    # A small learning rate like 1e-4 (0.0001) is a good starting point for fine-tuning.\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n",
        "    # The \"loss function\" calculates a score that measures how wrong the model's predictions are.\n",
        "    # The goal of training is to minimize this score. SparseCategoricalCrossentropy is the standard\n",
        "    # loss function for next-token prediction tasks.\n",
        "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    # Metrics are used to monitor the training process. Here, we'll track accuracy.\n",
        "    weighted_metrics=[keras.metrics.SparseCategoricalAccuracy()]\n",
        ")\n",
        "print(\"Done.\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-25T00:39:36.388761Z",
          "iopub.execute_input": "2025-08-25T00:39:36.389166Z",
          "iopub.status.idle": "2025-08-25T00:39:36.504977Z",
          "shell.execute_reply.started": "2025-08-25T00:39:36.389132Z",
          "shell.execute_reply": "2025-08-25T00:39:36.500380Z"
        },
        "id": "Ko9U4-GAA_Ot",
        "outputId": "9abf716d-461e-47ce-c3b5-1347f445834f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Compiling the model...\n",
            "Done.\n"
          ]
        }
      ],
      "execution_count": 12
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Starting fine-tuning...\")\n",
        "causal_lm.fit(formatted_data, epochs=10, batch_size=1) # Adjust batch_size depening on VRAM available. Adjust epoch until loss plateaus\n",
        "print(\"Fine-tuning complete!\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-25T00:39:38.321500Z",
          "iopub.execute_input": "2025-08-25T00:39:38.321860Z",
          "iopub.status.idle": "2025-08-25T00:40:41.495528Z",
          "shell.execute_reply.started": "2025-08-25T00:39:38.321829Z",
          "shell.execute_reply": "2025-08-25T00:40:41.489732Z"
        },
        "id": "C54lhve7A_Ot",
        "outputId": "a41b55e3-b44d-4bf5-c05d-0fe72bc086d6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting fine-tuning...\n",
            "Epoch 1/10\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 1s/step - loss: 0.8251 - sparse_categorical_accuracy: 0.5134\n",
            "Epoch 2/10\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 101ms/step - loss: 0.7462 - sparse_categorical_accuracy: 0.5284\n",
            "Epoch 3/10\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 88ms/step - loss: 0.6913 - sparse_categorical_accuracy: 0.5405\n",
            "Epoch 4/10\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 101ms/step - loss: 0.6982 - sparse_categorical_accuracy: 0.5483\n",
            "Epoch 5/10\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 100ms/step - loss: 0.6811 - sparse_categorical_accuracy: 0.5521\n",
            "Epoch 6/10\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 100ms/step - loss: 0.6649 - sparse_categorical_accuracy: 0.5623\n",
            "Epoch 7/10\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 100ms/step - loss: 0.6492 - sparse_categorical_accuracy: 0.5718\n",
            "Epoch 8/10\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 100ms/step - loss: 0.6329 - sparse_categorical_accuracy: 0.5808\n",
            "Epoch 9/10\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 100ms/step - loss: 0.6157 - sparse_categorical_accuracy: 0.5905\n",
            "Epoch 10/10\n",
            "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 100ms/step - loss: 0.5980 - sparse_categorical_accuracy: 0.5981\n",
            "Fine-tuning complete!\n"
          ]
        }
      ],
      "execution_count": 13
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test After Fine-Tuning\n",
        "Now, we ask the exact same prompt to our newly fine-tuned model. The hope is that its answer will be ~~better, more accurate~~ closer to what we have trained the model to do."
      ],
      "metadata": {
        "id": "HVKeZ_YYA_Ou"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Testing generation from the fine-tuned model:\")\n",
        "response_ft = causal_lm.generate(prompt)\n",
        "print(f\"{response_ft}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-25T00:40:41.497023Z",
          "iopub.execute_input": "2025-08-25T00:40:41.497307Z",
          "iopub.status.idle": "2025-08-25T00:41:00.864020Z",
          "shell.execute_reply.started": "2025-08-25T00:40:41.497277Z",
          "shell.execute_reply": "2025-08-25T00:41:00.858376Z"
        },
        "id": "mYgkkVXjA_Ou",
        "outputId": "7480664d-c3bf-4917-dc7a-cb1f0531bb7f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing generation from the fine-tuned model:\n",
            "What is pernicious anemia?\n",
            "\n",
            "Pernicious anemia is a condition in which the body does not produce enough of the vitamin B12 in the body. This deficiency can lead to various health problems.\n",
            "\n",
            "How pernicious anemia is caused.\n",
            "\n",
            "Pernicious anemia is caused by a deficiency in the vitamin B12 in the body. This vitamin is essential for the proper functioning of the nervous system, the heart, and the eyes. When the body doesn't have enough B12, it can't properly perform these functions.\n",
            "\n",
            "How pernicious anemia is treated.\n",
            "\n",
            "Treatment for pernicious anemia is usually done by a doctor. The doctor will prescribe a medication to help the body absorb the B12. The medication may help to prevent or treat other health problems. The medication may also help to prevent or treat pernicious anemia.\n",
            "The treatment for pernicious anemia is usually done by a doctor. The doctor will prescribe a medication to help the body absorb the B12. The medication may help to prevent or treat other health problems.\n",
            "How pernicious anemia is a condition.\n",
            "Pernicious anemia is a condition in which the body does not produce enough of the vitamin B12 in the body. This vitamin is essential for the proper functioning of the nervous system, the heart, and the eyes. When the body doesn't have enough B12, it can't properly perform these functions.\n",
            "In pernicious anemia, the body can't properly absorb the B12. This can lead to various health problems.\n",
            "In pernicious anemia, the body does not produce enough of the vitamin B12 in the body. This vitamin is essential for the proper functioning of the nervous system, the heart, and the eyes. When the body doesn't have enough B12, it can't properly perform these functions.\n",
            "In pernicious anemia, the body can't properly perform the nervous system, the heart, and the eyes.\n",
            "In pernicious anemia, the body can't properly absorb the B12. This can lead to various health problems.\n",
            "In pernicious anemia, the body does not produce enough of the vitamin B12 in the body. This vitamin is essential for the proper functioning of the nervous system, the heart, and the eyes. When the body doesn't have enough B12, it can't properly perform these functions.\n",
            "In pernicious anemia, the body can't properly perform the heart.\n",
            "In pernicious anemia, the body can't properly perform the eyes.\n",
            "In pernicious anemia, the body can't properly absorb the vitamin B12. This can lead to various health problems.\n",
            "In pernicious anemia, the body can't properly perform the nervous system.\n",
            "In pernicious anemia, the body can't properly absorb the vitamin B12. This can lead to various health problems.\n",
            "In pernicious anemia, the body can't properly perform the heart.\n",
            "In pernicious anemia, the body can't properly perform the eyes.\n",
            "In pernicious anemia, the body can't properly absorb the vitamin B12. This can lead to various health problems.\n",
            "In pernicious anemia, the body can't properly perform the nervous system.\n",
            "In pernicious anemia, the body can't properly absorb the vitamin B12. This can lead to various health problems.\n",
            "In pernicious anemia, the body does not produce enough of the vitamin B12 in the body. This vitamin is essential for the proper functioning of the nervous system, the heart, and the eyes. When the body doesn't have enough B12, it can't properly perform these functions.\n",
            "In pernicious anemia, the body can't properly perform the nervous system, the heart, and the eyes.\n",
            "In pernicious anemia, the body can't properly absorb the vitamin B12. This vitamin is essential for the proper functioning of the nervous system, the heart, and the eyes. When the body doesn't have enough B12, it can't properly perform these functions.\n",
            "In pernicious anemia, the body can't properly perform the heart.\n",
            "In pernicious anemia, the body can't properly perform the eyes.\n",
            "In pernicious anemia, the body can't properly absorb the vitamin B12. This can lead to various health problems.\n",
            "In pernicious anemia, the body can't properly perform the nervous system.\n",
            "In pernicious anemia, the body can't properly absorb the vitamin B12. This can lead to various health problems.\n",
            "In pernicious anemia, the body can't properly perform the heart.\n",
            "In pernicious anemia, the body can't properly perform the eyes.\n",
            "In pernicious anemia, the body can't properly absorb the vitamin B12. This can lead to various health problems.\n",
            "In pernicious anemia, the body can't properly perform the nervous system.\n",
            "In pernicious anemia, the body can't properly absorb the vitamin B12. This can lead to various health problems.\n",
            "In pernicious anemia, the body\n"
          ]
        }
      ],
      "execution_count": 16
    },
    {
      "cell_type": "code",
      "source": [
        "# And compare the scope of the fine-tuned model\n",
        "causal_lm.summary()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-25T00:41:00.865660Z",
          "iopub.execute_input": "2025-08-25T00:41:00.865951Z",
          "iopub.status.idle": "2025-08-25T00:41:00.912714Z",
          "shell.execute_reply.started": "2025-08-25T00:41:00.865892Z",
          "shell.execute_reply": "2025-08-25T00:41:00.908129Z"
        },
        "id": "hMfBvJyZA_Ou",
        "outputId": "0972980d-ccdd-4279-d475-e313096c85a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mPreprocessor: \"gemma3_causal_lm_preprocessor\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Preprocessor: \"gemma3_causal_lm_preprocessor\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                                                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m                                  Config\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ gemma3_tokenizer (\u001b[38;5;33mGemma3Tokenizer\u001b[0m)                            │                      Vocab size: \u001b[38;5;34m262,144\u001b[0m │\n",
              "└───────────────────────────────────────────────────────────────┴──────────────────────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                                                  </span>┃<span style=\"font-weight: bold\">                                   Config </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ gemma3_tokenizer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Gemma3Tokenizer</span>)                            │                      Vocab size: <span style=\"color: #00af00; text-decoration-color: #00af00\">262,144</span> │\n",
              "└───────────────────────────────────────────────────────────────┴──────────────────────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"gemma3_causal_lm\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"gemma3_causal_lm\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ padding_mask (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
              "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
              "│ token_ids (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
              "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
              "│ gemma3_backbone               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m640\u001b[0m)         │     \u001b[38;5;34m269,167,232\u001b[0m │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n",
              "│ (\u001b[38;5;33mGemma3Backbone\u001b[0m)              │                           │                 │ token_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
              "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
              "│ token_embedding               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m262144\u001b[0m)      │     \u001b[38;5;34m167,772,160\u001b[0m │ gemma3_backbone[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "│ (\u001b[38;5;33mReversibleEmbedding\u001b[0m)         │                           │                 │                            │\n",
              "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ padding_mask (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
              "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
              "│ token_ids (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
              "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
              "│ gemma3_backbone               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">640</span>)         │     <span style=\"color: #00af00; text-decoration-color: #00af00\">269,167,232</span> │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Gemma3Backbone</span>)              │                           │                 │ token_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
              "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
              "│ token_embedding               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">262144</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">167,772,160</span> │ gemma3_backbone[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReversibleEmbedding</span>)         │                           │                 │                            │\n",
              "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m271,305,346\u001b[0m (1.01 GB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">271,305,346</span> (1.01 GB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,069,056\u001b[0m (4.08 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,069,056</span> (4.08 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m268,098,176\u001b[0m (1022.71 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">268,098,176</span> (1022.71 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m2,138,114\u001b[0m (8.16 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,138,114</span> (8.16 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 18
    },
    {
      "cell_type": "code",
      "source": [
        "#Save the model to disk!\n",
        "causal_lm.save_to_preset(\"./my-model-ft\")"
      ],
      "metadata": {
        "id": "zvJ63j6RmIUW"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Example 2: A Quick Look at GPT-2\n",
        "Here we want to highlight how the choice of a different model means we have to make different choices in our data and framework. And the absoulte bare minimum amount of code for model tuning."
      ],
      "metadata": {
        "id": "49sEF0ZoA_Ou"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load a GPT2 backbone with pre-trained weights. NOTE the differnet keras_hub.models method!\n",
        "causal_lm = keras_hub.models.CausalLM.from_preset(path_gpt)\n",
        "\n",
        "prompt = \"What is pernicious anemia?\"\n",
        "causal_lm.generate(prompt)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-25T00:41:00.914947Z",
          "iopub.execute_input": "2025-08-25T00:41:00.915411Z",
          "iopub.status.idle": "2025-08-25T00:41:27.592597Z",
          "shell.execute_reply.started": "2025-08-25T00:41:00.915386Z",
          "shell.execute_reply": "2025-08-25T00:41:27.586847Z"
        },
        "id": "Eq6QicRrA_Ou",
        "outputId": "2eeecdb8-7a50-4fe5-e6d1-6d85a8193213",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"What is pernicious anemia?\\n\\nAnemia is an abnormal form of anemia. It can be caused by a deficiency of iron in the blood, a lack of iron in the body's blood, or by any of the following factors:\\n\\nA lack of oxygen\\n\\nA lack of calcium\\n\\nA lack of iron in the blood\\n\\nA lack of vitamin A\\n\\nThe most common cause of anemia is a buildup of plaque in the blood. These buildup are called pernicious anemia.\\n\\nPernicious anemia is caused by a deficiency of iron in the blood. It can be caused by a deficiency of iron in the blood, a lack of iron in the body's blood, or by any of the following factors:\\n\\nA lack of oxygen\\n\\nA lack of calcium\\n\\nA lack of vitamin A\\n\\nThe most common cause of anemia is a buildup of plaque in the blood. These buildup are called pernicious anemia.\\n\\nPernicious anemia is caused by a deficiency of iron in the blood. It can be caused by a deficiency of iron in the blood, a lack of iron in the body's blood, or by any of the following factors:\\n\\nA lack of oxygen\\n\\nA lack of calcium\\n\\nA lack of vitamin A\\n\\nThe most common cause of anemia is a buildup of plaque in the blood. These buildup are called pernicious anemia.\\n\\nPernicious anemia is caused by a deficiency of iron in the blood. It can be caused by a deficiency of iron in the blood, a lack of iron in the body's blood, or by any of the following factors:\\n\\nA lack of oxygen\\n\\nA lack of calcium\\n\\nA lack of vitamin A\\n\\nThe most common cause of anemia is a buildup of plaque in the blood. These buildup are called pernicious anemia.\\n\\nPernicious anemia is caused by a deficiency of iron in the blood. It can be caused by a deficiency of iron in the blood, a lack of iron in the body's blood, or by any of the following factors:\\n\\nA lack of oxygen\\n\\nA lack of calcium\\n\\nA lack of vitamin A\\n\\nThe most common cause of anemia is a buildup of plaque in the blood. These buildup are called pernicious anemia.\\n\\nPernicious anemia is caused by a deficiency of iron in the blood. It can be caused by a deficiency of iron in the blood, a lack of iron in the body's blood, or by any of the following factors:\\n\\nA lack of oxygen\\n\\nA lack of calcium\\n\\nA lack of vitamin A\\n\\nThe most common cause of anemia is a buildup of plaque in the blood. These buildup are called pernicious anemia.\\n\\nPernicious anemia is caused by a deficiency of iron in the blood. It can be caused by a deficiency of iron in the blood, a lack of iron in the body's blood, or by any of the following factors:\\n\\nA lack of oxygen\\n\\nA lack of calcium\\n\\nA lack of vitamin A\\n\\nThe most common cause of anemia is a buildup of plaque in the blood. These buildup are called pernicious anemia.\\n\\nPernicious anemia is caused by a deficiency of iron in the blood. It can be caused by a deficiency of iron in the blood, a lack of iron in the body's blood, or by any of the following factors:\\n\\nA lack of oxygen\\n\\nA lack of calcium\\n\\nA lack of vitamin A\\n\\nThe most commonly used drugs for pernicious anemia include:\\n\\nProzac\\n\\nProzac is used to treat anemia. It is the main active ingredient in the drug, which is a powerful anti-inflammatory. Prozac can be used to treat the most serious forms of anemia. The drug can also help to treat some of the more common types of anemia in the general population, such as type 2 diabetes, heart failure, and cancer.\\n\\nProzac is used to treat anemia. It is the main active ingredient in the drug, which is a powerful anti-inflammatory. Prozac can be used to treat the most serious forms of anemia. The drug can also help to treat some of the more common types of anemia in the general population, such as type 2 diabetes, heart failure, and cancer. Prozac has been shown to improve blood flow to the heart, and to improve the blood flow to a heart muscle (the heart muscle that controls blood flow to the brain, which is responsible for the heart beating).\\n\\nProzac has been shown to improve blood flow to the heart, and to improve the blood flow to a heart muscle (the heart muscle that controls blood flow to the brain, which is responsible for the heart beating). Prozac has been found to improve muscle tone. Pro\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "execution_count": 20
    },
    {
      "cell_type": "code",
      "source": [
        "# Format the data into what GPT2 model expects - different to Gemma!\n",
        "def format_data_gpt2(df):\n",
        "    prompts = []\n",
        "    responses = []\n",
        "    for index, row in df.iterrows():\n",
        "        question = row['question']\n",
        "        response = row['answer']\n",
        "        if question and response:\n",
        "             responses.append(f\"{response}\\n\")\n",
        "\n",
        "    return responses\n",
        "\n",
        "formatted_data_gpt2 = format_data_gpt2(df_subset)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-25T00:41:27.594694Z",
          "iopub.execute_input": "2025-08-25T00:41:27.594928Z",
          "iopub.status.idle": "2025-08-25T00:41:27.608014Z",
          "shell.execute_reply.started": "2025-08-25T00:41:27.594905Z",
          "shell.execute_reply": "2025-08-25T00:41:27.602936Z"
        },
        "id": "qadADDHnA_Ou"
      },
      "outputs": [],
      "execution_count": 21
    },
    {
      "cell_type": "code",
      "source": [
        "# Just use the defaults to demonstrate how lean our model training can be! (No LORA - so full fine tuning)\n",
        "causal_lm.compile()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-25T00:41:27.608809Z",
          "iopub.execute_input": "2025-08-25T00:41:27.609061Z",
          "iopub.status.idle": "2025-08-25T00:41:27.708640Z",
          "shell.execute_reply.started": "2025-08-25T00:41:27.609036Z",
          "shell.execute_reply": "2025-08-25T00:41:27.703045Z"
        },
        "id": "WC0oz0LaA_Ou"
      },
      "outputs": [],
      "execution_count": 22
    },
    {
      "cell_type": "code",
      "source": [
        "causal_lm.fit(formatted_data_gpt2, epochs=10, batch_size=7)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-25T00:41:27.710942Z",
          "iopub.execute_input": "2025-08-25T00:41:27.711188Z",
          "iopub.status.idle": "2025-08-25T00:43:35.420026Z",
          "shell.execute_reply.started": "2025-08-25T00:41:27.711166Z",
          "shell.execute_reply": "2025-08-25T00:43:35.413768Z"
        },
        "id": "BWyCXeZpA_Ou",
        "outputId": "904e424e-ec54-4976-b081-1adff6e231bc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 23s/step - loss: 1.0016 - sparse_categorical_accuracy: 0.5545\n",
            "Epoch 2/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 1s/step - loss: 0.9332 - sparse_categorical_accuracy: 0.5802\n",
            "Epoch 3/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - loss: 0.9064 - sparse_categorical_accuracy: 0.5795\n",
            "Epoch 4/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - loss: 0.8824 - sparse_categorical_accuracy: 0.5924\n",
            "Epoch 5/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - loss: 0.8623 - sparse_categorical_accuracy: 0.5959\n",
            "Epoch 6/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - loss: 0.8384 - sparse_categorical_accuracy: 0.6072\n",
            "Epoch 7/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - loss: 0.8232 - sparse_categorical_accuracy: 0.6092\n",
            "Epoch 8/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - loss: 0.8111 - sparse_categorical_accuracy: 0.6094\n",
            "Epoch 9/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - loss: 0.7914 - sparse_categorical_accuracy: 0.6186\n",
            "Epoch 10/10\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - loss: 0.7788 - sparse_categorical_accuracy: 0.6255\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7b01cfd66900>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "execution_count": 23
    },
    {
      "cell_type": "code",
      "source": [
        "# Try again with fine tuned model\n",
        "causal_lm.generate(prompt)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-25T00:43:35.423432Z",
          "iopub.execute_input": "2025-08-25T00:43:35.423724Z",
          "iopub.status.idle": "2025-08-25T00:43:44.487713Z",
          "shell.execute_reply.started": "2025-08-25T00:43:35.423698Z",
          "shell.execute_reply": "2025-08-25T00:43:44.483886Z"
        },
        "id": "u5-p3RcMA_Ou",
        "outputId": "1d67cacd-c859-4a9d-b334-031272c1cca4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"What is pernicious anemia?\\n\\nPernicious anemia is an infection of the central nervous system caused by a type of cancer called a cancer called Mycoplasma gondii. The disease is a type of cancer that can cause a variety of health problems, including heart disease, type 2 diabetes, and cancers of the thyroid and lung.\\n\\nThe most common types of cancer in people are breast, prostate, and lung cancer. The disease affects the central nervous system, including those areas of the body where nerves and nerves play important roles.\\n\\nThe cause of pernicious anemia is not well understood. But a number of studies have identified a number of possible causes, including:\\n\\nHemorrhagic anemia\\n\\nHepatic anemia\\n\\nHepatic cell carcinoma\\n\\nTubercular anemia\\n\\nChronic wasting syndrome (CWS).\\n\\nWhat causes pernicious anemia?\\n\\nA person may develop pernicious anemia because of an abnormal immune response to a protein called the T helper protein. T cells attack the central nervous system and attack the immune system's ability to fight off invading invaders.\\n\\nThe protein is found in the body's own cells, called myelin, which surrounds nerves. Myelin is a protective layer of protein that helps cells fight off foreign invaders.\\n\\nPeople with chronic wasting syndrome have less myelin in their cells than people with normal immune responses and have fewer immune responses.\\n\\nT cells are responsible for the central nervous system's ability to fight off foreign invaders. They attack the cells in the body's immune system by invading proteins called T-cell lymphocytes (T-L1). When T cells attack cells, they release a hormone called an anti-inflammatory factor called T-galactose (tGA) that helps cells make antibodies to protect against the foreign invaders.\\n\\nIn the brain, T-galactose is used to fight infections and helps the immune system fight off infections. T-galactose also helps the body fight off certain cancers, such as type 1 diabetes and type 2 diabetes.\\n\\nT-galactose is used in the brain as a part of an immune system defense against infections that can cause cancer.\\n\\nWhat causes pernicious anemia?\\n\\nA person who develops pernicious anemia can have anemia that is more severe than what's normally seen.\\n\\nThe cause of pernicious anemia can vary, but the most common causes of pernicious anemia are:\\n\\nA genetic abnormality or genetic defect\\n\\nAn inherited disorder that can cause the disease\\n\\nA condition in which the person's immune system doesn't work properly\\n\\nA condition that is not properly treated\\n\\nA condition that is not caused by other causes that can cause the condition\\n\\nWhat are the signs and symptoms of pernicious anemia?\\n\\nThe signs and symptoms of pernicious anemia are similar to other autoimmune disorders that affect the body's immune system.\\n\\nYour doctor or health care provider can treat your condition with a combination of medications, including antacids, antihistamines, antihistamines, and antithyroid medication.\\n\\nYour doctor or health care provider may also talk with your family doctor or a doctor at home.\\n\\nWhat is the cause of pernicious anemia?\\n\\nThe cause of pernicious anemia can be treated with medicines or other medicines, such as anticholinergic medications. These medicines are taken to treat a wide array of diseases, including autoimmune diseases, diabetes, and cancer.\\n\\nWhat are the signs and symptoms of pernicious anemia?\\n\\nYour doctor or health care provider will ask you to take a blood thinners (bovine serum albumin) every two to three hours. Your doctor or health care provider will take you to your doctor's office for a complete checkup.\\n\\nYour doctor or health care provider may also take you to the doctor's office to talk with you.\\n\\nYour doctor or health care provider may also ask you about your medical history and ask about the signs and symptoms of the condition.\\n\\nWhat is the cause of pernicious anemia?\\n\\nYour doctor or health care provider may treat a number of conditions with anticholinergic medications, including:\\n\\nHemorrhagic anemia\\n\\nChronic wasting syndrome (CWS)\\n\\nTubercular anemia\\n\\nTubercular carcinoma\\n\\nTysinophiligo\\n\\nTuberculoskeletal pain (TMP)\\n\\nTuberculomyelitis\\n\\nVaginal anemia\\n\\nOther causes of pernicious anemia include:\\n\\nOther causes of pernicious anemia that cause a change in the central nervous system\\n\\nOther causes of an autoimmune disorder that affect the central nervous system\\n\\nOther causes of a genetic disorder or genetic disorder that affect the central\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# How You Can Adapt This For Your Research\n",
        "\n",
        "The examples above use a medical question-answering dataset, but the workflow is highly adaptable.\n",
        "\n",
        "Understand your task. Pick a model. Pick a framework.  Build your pipeline!\n",
        "\n",
        "The key is to structure your data into what your framework/model requires, that also teaches the model how to perform the task you want.\n",
        "\n",
        "## Links:\n",
        "KerasHub Documentation: https://keras.io/keras_hub/api/models/gemma3/\n",
        "\n",
        "Good Huggingface training demo: https://www.youtube.com/watch?v=uikZs6y0qgI\n",
        "\n",
        "Gemma 3 fine tune documentation: https://ai.google.dev/gemma/docs/core/lora_tuning\n",
        "\n",
        "Gemma 3 on Kaggle: https://www.kaggle.com/models/google/gemma-3\n",
        "\n",
        "GPT-2 on Kaggle: https://www.kaggle.com/models/keras/gpt2\n",
        "\n",
        "Fine Tune Gemini: https://cloud.google.com/vertex-ai/generative-ai/docs/models/gemini-use-supervised-tuning (deprecated AI studio method: https://ai.google.dev/gemini-api/docs/model-tuning)\n",
        "\n",
        "Huggingface Transformers documentation: https://huggingface.co/docs/transformers/en/index\n",
        "\n",
        "Huggingface Sentence-Transformers documentation: https://huggingface.co/sentence-transformers"
      ],
      "metadata": {
        "id": "4yn3oqQGA_Ov"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lfomlR9upRtN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}